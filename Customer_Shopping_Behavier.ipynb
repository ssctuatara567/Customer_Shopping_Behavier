# 1.Táº£i vÃ  hiá»ƒn thá»‹ dá»¯ liá»‡u

## 1.1 Táº£i dá»¯ liá»‡u vá» notebook

import zipfile
import os
from google.colab import files

# BÆ°á»›c 1: Upload file tá»« mÃ¡y tÃ­nh
print("Vui lÃ²ng chá»n file .zip tá»« mÃ¡y tÃ­nh cá»§a báº¡n...")
uploaded = files.upload()

# BÆ°á»›c 2: Tá»± Ä‘á»™ng tÃ¬m file zip vá»«a upload vÃ  giáº£i nÃ©n
for filename in uploaded.keys():
    if filename.endswith('.zip'):
        print(f"\nÄang giáº£i nÃ©n file: {filename} ...")

        # Táº¡o Ä‘Æ°á»ng dáº«n giáº£i nÃ©n (giáº£i nÃ©n ngay táº¡i thÆ° má»¥c hiá»‡n táº¡i)
        with zipfile.ZipFile(filename, 'r') as zip_ref:
            zip_ref.extractall(".")

        print("âœ… Giáº£i nÃ©n thÃ nh cÃ´ng!")

        # Liá»‡t kÃª cÃ¡c file sau khi giáº£i nÃ©n Ä‘á»ƒ kiá»ƒm tra
        print("\nDanh sÃ¡ch cÃ¡c file trong thÆ° má»¥c:")
        print(os.listdir("."))
    else:
        print(f"File {filename} khÃ´ng pháº£i lÃ  file .zip")

## 1.2 Thá»‘ng kÃª vÃ  bÃ¡o cÃ¡o tÃ¬nh tráº¡ng cá»§a bá»™ dá»¯ liá»‡u

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# --- 1. Äá»ŒC Dá»® LIá»†U ---
df = pd.read_csv('shopping_behavior_updated.csv')

# --- 2. KHÃM PHÃ Cáº¤U TRÃšC ---
print("=== 5 DÃ’NG Äáº¦U TIÃŠN ===")
display(df.head())  # Hiá»ƒn thá»‹ Ä‘áº¹p hÆ¡n print trong Colab

print("\n=== THÃ”NG TIN Cá»˜T VÃ€ KIá»‚U Dá»® LIá»†U ===")
df.info()

print(f"\n=== KÃCH THÆ¯á»šC Dá»® LIá»†U: {df.shape} ===")


| TÃªn Cá»™t (Column Name) | Ã NghÄ©a (Meaning) | Kiá»ƒu Dá»¯ Liá»‡u | VÃ­ Dá»¥ GiÃ¡ Trá»‹ (Example Values) |
| :--- | :--- | :--- | :--- |
| **Customer ID** | MÃ£ Ä‘á»‹nh danh duy nháº¥t cá»§a khÃ¡ch hÃ ng | Integer | `1`, `2`, `3900` |
| **Age** | Äá»™ tuá»•i cá»§a khÃ¡ch hÃ ng | Integer | `18`, `25`, `60` |
| **Gender** | Giá»›i tÃ­nh | String | `Male`, `Female` |
| **Item Purchased** | TÃªn sáº£n pháº©m Ä‘Ã£ mua | String | `Blouse`, `Jeans`, `Sneakers` |
| **Category** | Danh má»¥c sáº£n pháº©m | String | `Clothing`, `Footwear`, `Accessories` |
| **Purchase Amount (USD)** | Sá»‘ tiá»n thanh toÃ¡n (USD) | Float/Int | `20`, `55`, `100` |
| **Location** | Äá»‹a Ä‘iá»ƒm (Bang/ThÃ nh phá»‘) | String | `Kentucky`, `Maine` |
| **Size** | KÃ­ch cá»¡ sáº£n pháº©m | String | `S`, `M`, `L`, `XL` |
| **Color** | MÃ u sáº¯c sáº£n pháº©m | String | `Gray`, `Maroon`, `White` |
| **Season** | MÃ¹a giao dá»‹ch diá»…n ra | String | `Winter`, `Spring`, `Summer` |
| **Review Rating** | Äiá»ƒm Ä‘Ã¡nh giÃ¡ (sao) | Float | `3.1`, `4.5`, `5.0` |
| **Subscription Status** | Tráº¡ng thÃ¡i Ä‘Äƒng kÃ½ thÃ nh viÃªn | String | `Yes`, `No` |
| **Payment Method** | PhÆ°Æ¡ng thá»©c thanh toÃ¡n | String | `Credit Card`, `PayPal`, `Cash` |
| **Shipping Type** | HÃ¬nh thá»©c váº­n chuyá»ƒn | String | `Express`, `Free Shipping` |
| **Discount Applied** | CÃ³ Ã¡p dá»¥ng giáº£m giÃ¡ khÃ´ng | String | `Yes`, `No` |
| **Promo Code Used** | CÃ³ dÃ¹ng mÃ£ khuyáº¿n mÃ£i khÃ´ng | String | `Yes`, `No` |
| **Previous Purchases** | Sá»‘ Ä‘Æ¡n hÃ ng Ä‘Ã£ mua trÆ°á»›c Ä‘Ã¢y | Integer | `1`, `14`, `50` |
| **Frequency of Purchases** | Táº§n suáº¥t mua hÃ ng | String | `Weekly`, `Bi-Weekly`, `Annually` |


# --- 3. KIá»‚M TRA Lá»–I Dá»® LIá»†U (MISSING & DUPLICATE) ---
print("\n=== KIá»‚M TRA GIÃ TRá»Š Bá»Š THIáº¾U (NULL) ===")
missing = df.isnull().sum()
# Chá»‰ in ra cÃ¡c cá»™t cÃ³ lá»—i thiáº¿u
if missing.sum() > 0:
    print(missing[missing > 0])
else:
    print("âœ… KhÃ´ng cÃ³ giÃ¡ trá»‹ bá»‹ thiáº¿u (Null/NaN).")

print("\n=== KIá»‚M TRA DÃ’NG TRÃ™NG Láº¶P (DUPLICATE) ===")
duplicates = df.duplicated().sum()
print(f"Sá»‘ lÆ°á»£ng dÃ²ng trÃ¹ng láº·p: {duplicates}")

# --- 4. THá»NG KÃŠ MÃ” Táº¢ & NGOáº I LAI (OUTLIERS) ---
print("\n=== THá»NG KÃŠ CÆ  Báº¢N (Mean, Min, Max...) ===")
display(df.describe())

# --- 5. Váº¼ BIá»‚U Äá»’ BOXPLOT Äá»‚ TÃŒM NGOáº I LAI ---
# Lá»c láº¥y cÃ¡c cá»™t dá»¯ liá»‡u sá»‘ (loáº¡i bá» Customer ID vÃ¬ khÃ´ng cáº§n check outlier)
numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
if 'Customer ID' in numeric_cols:
    numeric_cols = numeric_cols.drop('Customer ID')

if len(numeric_cols) > 0:
    print("\n=== BIá»‚U Äá»’ BOXPLOT CHECK NGOáº I LAI ===")
    plt.figure(figsize=(15, 5))
    for i, col in enumerate(numeric_cols):
        plt.subplot(1, len(numeric_cols), i+1)
        sns.boxplot(y=df[col], color='skyblue')
        plt.title(f'Outliers: {col}')
        plt.grid(True, linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.show()
else:
    print("KhÃ´ng tÃ¬m tháº¥y cá»™t sá»‘ nÃ o phÃ¹ há»£p Ä‘á»ƒ váº½ Boxplot.")

Tuá»•i (Age):

Dáº£i tuá»•i tá»« 18 Ä‘áº¿n 70.

Trung bÃ¬nh (Mean) lÃ  44 tuá»•i, vÃ  trung vá»‹ (50%) cÅ©ng lÃ  44. Sá»± trÃ¹ng khá»›p nÃ y gá»£i Ã½ dá»¯ liá»‡u tuá»•i Ä‘Æ°á»£c phÃ¢n bá»‘ ráº¥t Ä‘á»“ng Ä‘á»u.

Sá»‘ tiá»n mua (Purchase Amount):

Tháº¥p nháº¥t lÃ  20 USD, cao nháº¥t lÃ  100 USD.

Trung bÃ¬nh khoáº£ng 60 USD.

ÄÃ¡nh giÃ¡ (Review Rating):

Thang Ä‘iá»ƒm tá»« 2.5 Ä‘áº¿n 5.0.

Äiá»ƒm trung bÃ¬nh lÃ  3.75, cho tháº¥y khÃ¡ch hÃ ng cÃ³ xu hÆ°á»›ng Ä‘Ã¡nh giÃ¡ khÃ¡ tÃ­ch cá»±c.

Sá»‘ láº§n mua trÆ°á»›c Ä‘Ã¢y (Previous Purchases):

Dao Ä‘á»™ng tá»« 1 Ä‘áº¿n 50 láº§n.


Biá»ƒu Ä‘á»“ há»™p (Boxplots) - Kiá»ƒm tra ngoáº¡i lai (Outliers)
================================================================================
Bá»‘n biá»ƒu Ä‘á»“ Boxplot bÃªn dÆ°á»›i dÃ¹ng Ä‘á»ƒ phÃ¡t hiá»‡n cÃ¡c giÃ¡ trá»‹ báº¥t thÆ°á»ng (outliers):

Nháº­n xÃ©t chung: Cáº£ 4 biá»ƒu Ä‘á»“ (Age, Purchase Amount, Review Rating, Previous Purchases) Ä‘á»u khÃ´ng xuáº¥t hiá»‡n cÃ¡c Ä‘iá»ƒm Ä‘en (outliers) náº±m ngoÃ i hai Ä‘áº§u rÃ¢u (whiskers).

HÃ¬nh dÃ¡ng: CÃ¡c há»™p (box) náº±m khÃ¡ cÃ¢n Ä‘á»‘i á»Ÿ giá»¯a, vÃ  hai rÃ¢u trÃªn/dÆ°á»›i dÃ i tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhau.

Ã nghÄ©a: Dá»¯ liá»‡u nÃ y cá»±c ká»³ "sáº¡ch" vÃ  phÃ¢n bá»‘ Ä‘á»“ng Ä‘á»u (Uniform Distribution). Äiá»u nÃ y thÆ°á»ng tháº¥y á»Ÿ cÃ¡c bá»™ dá»¯ liá»‡u giáº£ láº­p (synthetic datasets) dÃ¹ng cho má»¥c Ä‘Ã­ch há»c táº­p, vÃ¬ dá»¯ liá»‡u thá»±c táº¿ thÆ°á»ng sáº½ cÃ³ Ä‘á»™ lá»‡ch (skewness) hoáº·c vÃ i giÃ¡ trá»‹ ngoáº¡i lai.

#Descriptive EDA

##PhÃ¢n tÃ­ch phÃ¢n bá»‘ cá»§a cÃ¡c biáº¿n sá»‘ (Numerical Variables)

import matplotlib.pyplot as plt
import seaborn as sns

# Thiáº¿t láº­p giao diá»‡n biá»ƒu Ä‘á»“
sns.set_style("whitegrid")
plt.figure(figsize=(18, 5))

# 1. PhÃ¢n bá»‘ Äá»™ tuá»•i (Age)
plt.subplot(1, 3, 1)
sns.histplot(df['Age'], bins=20, kde=True, color='skyblue')
plt.title('PhÃ¢n bá»‘ Äá»™ tuá»•i KhÃ¡ch hÃ ng')
plt.xlabel('Tuá»•i')
plt.ylabel('Sá»‘ lÆ°á»£ng')

# 2. PhÃ¢n bá»‘ Sá»‘ tiá»n chi tiÃªu (Purchase Amount)
plt.subplot(1, 3, 2)
sns.histplot(df['Purchase Amount (USD)'], bins=20, kde=True, color='salmon')
plt.title('PhÃ¢n bá»‘ Sá»‘ tiá»n chi tiÃªu (USD)')
plt.xlabel('Sá»‘ tiá»n (USD)')
plt.ylabel('Sá»‘ lÆ°á»£ng giao dá»‹ch')

# 3. PhÃ¢n bá»‘ Äiá»ƒm Ä‘Ã¡nh giÃ¡ (Review Rating)
plt.subplot(1, 3, 3)
sns.histplot(df['Review Rating'], bins=10, kde=True, color='green')
plt.title('PhÃ¢n bá»‘ Äiá»ƒm Ä‘Ã¡nh giÃ¡')
plt.xlabel('Äiá»ƒm (Rating)')
plt.ylabel('Sá»‘ lÆ°á»£ng')

plt.tight_layout()
plt.show()

##PhÃ¢n tÃ­ch cÃ¡c biáº¿n phÃ¢n loáº¡i (Categorical Variables)

fig, axes = plt.subplots(2, 2, figsize=(16, 10))

# 1. Tá»· lá»‡ Giá»›i tÃ­nh
sns.countplot(ax=axes[0, 0], x='Gender', data=df, palette='pastel')
axes[0, 0].set_title('Sá»‘ lÆ°á»£ng khÃ¡ch hÃ ng theo Giá»›i tÃ­nh')
for container in axes[0, 0].containers:
    axes[0, 0].bar_label(container)

# 2. Sá»‘ lÆ°á»£ng mua theo Danh má»¥c (Category)
sns.countplot(ax=axes[0, 1], y='Category', data=df, order=df['Category'].value_counts().index, palette='viridis')
axes[0, 1].set_title('Sá»‘ lÆ°á»£ng Ä‘Æ¡n hÃ ng theo Danh má»¥c')
axes[0, 1].set_xlabel('Sá»‘ lÆ°á»£ng')

# 3. MÃ¹a mua sáº¯m (Season)
sns.countplot(ax=axes[1, 0], x='Season', data=df, order=['Spring', 'Summer', 'Fall', 'Winter'], palette='coolwarm')
axes[1, 0].set_title('Mua sáº¯m theo MÃ¹a')

# 4. PhÆ°Æ¡ng thá»©c thanh toÃ¡n
sns.countplot(ax=axes[1, 1], y='Payment Method', data=df, order=df['Payment Method'].value_counts().index, palette='magma')
axes[1, 1].set_title('PhÆ°Æ¡ng thá»©c thanh toÃ¡n phá»• biáº¿n')

plt.tight_layout()
plt.show()

##PhÃ¢n tÃ­ch má»‘i quan há»‡ (Chi tiÃªu trung bÃ¬nh)

# TÃ­nh toÃ¡n sá»‘ tiá»n chi tiÃªu trung bÃ¬nh
print("=== CHI TIÃŠU TRUNG BÃŒNH (USD) THEO DANH Má»¤C VÃ€ GIá»šI TÃNH ===")

# NhÃ³m theo Category vÃ  Gender, tÃ­nh trung bÃ¬nh cá»™t Purchase Amount
pivot_table = df.groupby(['Category', 'Gender'])['Purchase Amount (USD)'].mean().unstack()
display(pivot_table.style.background_gradient(cmap='YlOrRd', axis=None).format("{:.2f}"))

# Váº½ biá»ƒu Ä‘á»“ trá»±c quan hÃ³a báº£ng trÃªn
plt.figure(figsize=(10, 6))
sns.barplot(data=df, x='Category', y='Purchase Amount (USD)', hue='Gender', ci=None, palette='muted')
plt.title('Chi tiÃªu trung bÃ¬nh theo Danh má»¥c vÃ  Giá»›i tÃ­nh')
plt.ylabel('Chi tiÃªu trung bÃ¬nh (USD)')
plt.show()

#Tiá»n xá»­ lÃ­ dá»¯ liá»‡u

Dá»¯ liá»‡u  ká»³ sáº¡ch.

KhÃ´ng cÃ³ giÃ¡ trá»‹ thiáº¿u (Null).

KhÃ´ng cÃ³ dÃ²ng trÃ¹ng láº·p.

CÃ¡c giÃ¡ trá»‹ trong cá»™t chá»¯ (Category, Gender...) Ä‘á»u chuáº©n, khÃ´ng bá»‹ lá»—i chÃ­nh táº£ hay khoáº£ng tráº¯ng thá»«a.

Káº¿ hoáº¡ch Tiá»n xá»­ lÃ½:

XÃ³a Customer ID: Cá»™t nÃ y vÃ´ nghÄ©a trong phÃ¢n tÃ­ch.

Xá»­ lÃ½ biáº¿n cÃ³ thá»© tá»± (Ordinal Encoding):

Size: S < M < L < XL. Cáº§n gÃ¡n sá»‘ tÆ°Æ¡ng á»©ng (1, 2, 3, 4).

Frequency of Purchases: Weekly > Monthly > Annually... Cáº§n chuyá»ƒn Ä‘á»•i thÃ nh táº§n suáº¥t (sá»‘ láº§n/nÄƒm) Ä‘á»ƒ Ä‘o lÆ°á»ng Ä‘á»™ lá»›n.

Xá»­ lÃ½ biáº¿n Yes/No: Chuyá»ƒn thÃ nh 1 vÃ  0.

MÃ£ hÃ³a cÃ¡c biáº¿n danh má»¥c cÃ²n láº¡i (Label Encoding): Gender, Category, Season... chuyá»ƒn sang sá»‘.

import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Táº¡o báº£n sao Ä‘á»ƒ khÃ´ng áº£nh hÆ°á»Ÿng dá»¯ liá»‡u gá»‘c
df_clean = df.copy()

# 1. XÃ³a cá»™t khÃ´ng cáº§n thiáº¿t
if 'Customer ID' in df_clean.columns:
    df_clean.drop('Customer ID', axis=1, inplace=True)

# 2. Xá»­ lÃ½ thá»§ cÃ´ng cÃ¡c cá»™t cÃ³ thá»© tá»± (Ordinal)
# Mapping cho Size
size_map = {'S': 1, 'M': 2, 'L': 3, 'XL': 4}
df_clean['Size'] = df_clean['Size'].map(size_map)

# Mapping cho Táº§n suáº¥t mua hÃ ng (Quy Ä‘á»•i ra sá»‘ láº§n/nÄƒm Æ°á»›c tÃ­nh)
freq_map = {
    'Weekly': 52,
    'Bi-Weekly': 26,
    'Fortnightly': 26,  # TÆ°Æ¡ng Ä‘Æ°Æ¡ng Bi-Weekly
    'Monthly': 12,
    'Quarterly': 4,
    'Every 3 Months': 4,
    'Annually': 1
}
df_clean['Frequency of Purchases'] = df_clean['Frequency of Purchases'].map(freq_map)

# 3. Xá»­ lÃ½ cÃ¡c cá»™t Yes/No -> 1/0
binary_cols = ['Subscription Status', 'Discount Applied', 'Promo Code Used']
for col in binary_cols:
    df_clean[col] = df_clean[col].map({'Yes': 1, 'No': 0})

# 4. MÃ£ hÃ³a cÃ¡c cá»™t danh má»¥c cÃ²n láº¡i (Label Encoding)
# CÃ¡c cá»™t nÃ y khÃ´ng cÃ³ thá»© tá»± cá»¥ thá»ƒ (Nam/Ná»¯, MÃ¹a, PhÆ°Æ¡ng thá»©c thanh toÃ¡n...)
categorical_cols = df_clean.select_dtypes(include=['object']).columns
le = LabelEncoder()

print("Äang mÃ£ hÃ³a cÃ¡c cá»™t sau:")
for col in categorical_cols:
    print(f"- {col}")
    df_clean[col] = le.fit_transform(df_clean[col])

# --- KIá»‚M TRA Káº¾T QUáº¢ ---
print("\n=== Dá»® LIá»†U SAU KHI TIá»€N Xá»¬ LÃ ===")
display(df_clean.head())
print("\n=== KIá»‚U Dá»® LIá»†U ===")
df_clean.info()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(16, 12))
# TÃ­nh ma tráº­n tÆ°Æ¡ng quan
corr_matrix = df_clean.corr()

# Váº½ Heatmap
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', linewidths=0.5)
plt.title('Biá»ƒu Ä‘á»“ nhiá»‡t tÆ°Æ¡ng quan (Correlation Heatmap)')
plt.show()

#MÃ´ hÃ¬nh hÃ³a

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# 1. CHUáº¨N HÃ“A Dá»® LIá»†U (Scaling)
# ChÃºng ta sáº½ dÃ¹ng báº£n sao df_clean Ä‘á»ƒ khÃ´ng lÃ m há»ng dá»¯ liá»‡u gá»‘c
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_clean)

# 2. TÃŒM Sá» NHÃ“M Tá»I Æ¯U (PHÆ¯Æ NG PHÃP ELBOW)
inertia = []
K_range = range(1, 11) # Thá»­ chia tá»« 1 Ä‘áº¿n 10 nhÃ³m

print("Äang cháº¡y thuáº­t toÃ¡n K-Means Ä‘á»ƒ tÃ¬m Ä‘iá»ƒm tá»‘i Æ°u...")
for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(df_scaled)
    inertia.append(kmeans.inertia_)

# 3. Váº¼ BIá»‚U Äá»’ ELBOW
plt.figure(figsize=(10, 6))
plt.plot(K_range, inertia, marker='o', linestyle='--', color='b')
plt.title('PhÆ°Æ¡ng phÃ¡p Elbow (Khuá»·u tay) Ä‘á»ƒ chá»n sá»‘ nhÃ³m K')
plt.xlabel('Sá»‘ lÆ°á»£ng nhÃ³m (K)')
plt.ylabel('Inertia (Äá»™ lá»—i)')
plt.xticks(K_range)
plt.grid(True)
plt.show()

from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns

# Thiáº¿t láº­p danh sÃ¡ch cÃ¡c K cáº§n thá»­
k_candidates = [2, 3, 4]

# Chuáº©n bá»‹ biá»ƒu Ä‘á»“
fig, axes = plt.subplots(1, 3, figsize=(20, 6))

print("=== SO SÃNH HIá»†U QUáº¢ CÃC Cá»¤M (SILHOUETTE SCORE) ===")

for i, k in enumerate(k_candidates):
    # 1. Cháº¡y K-Means
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(df_scaled)

    # 2. TÃ­nh Ä‘iá»ƒm Silhouette (CÃ ng cao cÃ ng tá»‘t)
    score = silhouette_score(df_scaled, cluster_labels)
    print(f"- Vá»›i K = {k}: Silhouette Score = {score:.4f}")

    # 3. Giáº£m chiá»u dá»¯ liá»‡u xuá»‘ng 2D báº±ng PCA Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“
    pca = PCA(n_components=2)
    components = pca.fit_transform(df_scaled)

    # 4. Váº½ biá»ƒu Ä‘á»“ phÃ¢n cá»¥m
    sns.scatterplot(
        x=components[:, 0],
        y=components[:, 1],
        hue=cluster_labels,
        palette='viridis',
        ax=axes[i],
        s=50,
        alpha=0.6
    )
    axes[i].set_title(f'K = {k} (Score: {score:.3f})')
    axes[i].set_xlabel('PCA Component 1')
    axes[i].set_ylabel('PCA Component 2')
    axes[i].legend(title='Cluster')

plt.tight_layout()
plt.show()



Vá»›i K=2, thuáº­t toÃ¡n chia dá»¯ liá»‡u thÃ nh 2 pháº§n lá»›n (nhÃ³m bÃªn trÃ¡i vÃ  nhÃ³m bÃªn pháº£i khoáº£ng trá»‘ng nÃ y). ÄÃ¢y lÃ  cÃ¡ch chia tá»± nhiÃªn vÃ  rÃµ rÃ ng nháº¥t vá» máº·t khoáº£ng cÃ¡ch, giÃºp Ä‘iá»ƒm sá»‘ Silhouette cao nháº¥t.

Khi tÄƒng lÃªn K=3 hoáº·c K=4, thuáº­t toÃ¡n cá»‘ gáº¯ng chia nhá» cÃ¡c nhÃ³m dá»c (cÃ¡c dáº£i mÃ u) vá»‘n náº±m khÃ¡ sÃ¡t nhau, lÃ m giáº£m Ä‘á»™ tÃ¡ch biá»‡t trung bÃ¬nh giá»¯a cÃ¡c cá»¥m, dáº«n Ä‘áº¿n Ä‘iá»ƒm sá»‘ tháº¥p dáº§n.
====>K = 2 (Score: 0.1631): Cao nháº¥t. ÄÃ¢y lÃ  phÆ°Æ¡ng Ã¡n tá»‘t nháº¥t.

Máº·c dÃ¹ Ä‘iá»ƒm 0.16 khÃ´ng pháº£i lÃ  quÃ¡ cao (lÃ½ tÆ°á»Ÿng lÃ  > 0.5), nhÆ°ng vá»›i dá»¯ liá»‡u hÃ nh vi con ngÆ°á»i phá»©c táº¡p, Ä‘Ã¢y lÃ  chuyá»‡n bÃ¬nh thÆ°á»ng. ChÃºng ta sáº½ chá»n $K=2$ Ä‘á»ƒ phÃ¢n tÃ­ch.
==============================================================================



#PhÃ¢n tÃ­ch Ä‘áº·c Ä‘iá»ƒm tá»«ng nhÃ³m (Cluster Profiling)

# 1. Cháº¡y láº¡i KMeans vá»›i K=2 (Má»©c tá»‘i Æ°u nháº¥t)
kmeans_final = KMeans(n_clusters=2, random_state=42, n_init=10)
cluster_labels = kmeans_final.fit_predict(df_scaled)

# 2. GÃ¡n nhÃ£n nhÃ³m vÃ o dá»¯ liá»‡u Gá»C (df) Ä‘á»ƒ dá»… Ä‘á»c
# LÆ°u Ã½: ChÃºng ta dÃ¹ng df (dá»¯ liá»‡u ban Ä‘áº§u) Ä‘á»ƒ Ä‘á»c Ä‘Æ°á»£c 'Male', 'Female' thay vÃ¬ 0, 1
df_analysis = df.copy()
df_analysis['Cluster_Label'] = cluster_labels

# 3. TÃ­nh giÃ¡ trá»‹ trung bÃ¬nh cÃ¡c chá»‰ sá»‘ quan trá»ng cho tá»«ng nhÃ³m
# Chá»n cÃ¡c cá»™t sá»‘ quan trá»ng Ä‘á»ƒ so sÃ¡nh
numeric_cols = ['Age', 'Purchase Amount (USD)', 'Review Rating', 'Previous Purchases']
profile = df_analysis.groupby('Cluster_Label')[numeric_cols].mean()

# ThÃªm cá»™t sá»‘ lÆ°á»£ng khÃ¡ch hÃ ng trong má»—i nhÃ³m
profile['Customer_Count'] = df_analysis['Cluster_Label'].value_counts()

print("=== CHÃ‚N DUNG KHÃCH HÃ€NG THEO Tá»ªNG NHÃ“M (TRUNG BÃŒNH) ===")
display(profile.style.background_gradient(cmap='YlOrRd'))

# 4. Kiá»ƒm tra sá»± khÃ¡c biá»‡t vá» cÃ¡c biáº¿n Ä‘á»‹nh tÃ­nh (VÃ­ dá»¥: Giá»›i tÃ­nh, GÃ³i Ä‘Äƒng kÃ½)
print("\n=== Tá»¶ Lá»† GIá»šI TÃNH TRONG Tá»ªNG NHÃ“M ===")
print(pd.crosstab(df_analysis['Cluster_Label'], df_analysis['Gender'], normalize='index') * 100)

print("\n=== Tá»¶ Lá»† MUA GÃ“I SUBSCRIPTION (CÃ“/KHÃ”NG) ===")
print(pd.crosstab(df_analysis['Cluster_Label'], df_analysis['Subscription Status'], normalize='index') * 100)

import seaborn as sns
import matplotlib.pyplot as plt

# Danh sÃ¡ch cÃ¡c cá»™t muá»‘n so sÃ¡nh giá»¯a 2 nhÃ³m
features_to_compare = ['Age', 'Purchase Amount (USD)', 'Review Rating', 'Previous Purchases']

# Thiáº¿t láº­p lÆ°á»›i biá»ƒu Ä‘á»“ 2x2
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
axes = axes.flatten()

for i, col in enumerate(features_to_compare):
    # Váº½ Boxplot: Trá»¥c X lÃ  NhÃ³m (0, 1), Trá»¥c Y lÃ  giÃ¡ trá»‹ cá»™t
    sns.boxplot(x='Cluster_Label', y=col, data=df_analysis, ax=axes[i], palette="Set2")
    axes[i].set_title(f'So sÃ¡nh {col} giá»¯a cÃ¡c nhÃ³m')
    axes[i].set_xlabel('NhÃ³m khÃ¡ch hÃ ng (Cluster)')

plt.tight_layout()
plt.show()

# Kiá»ƒm tra thÃªm biáº¿n Ä‘á»‹nh tÃ­nh quan trá»ng: Subscription Status
plt.figure(figsize=(8, 5))
sns.countplot(x='Cluster_Label', hue='Subscription Status', data=df_analysis, palette='pastel')
plt.title('Sá»‘ lÆ°á»£ng ngÆ°á»i cÃ³ Subscription theo tá»«ng nhÃ³m')
plt.show()

Vá»›i K=2: PhÃ¢n loáº¡i theo "Tráº¡ng thÃ¡i ÄÄƒng kÃ½"
============================================================================
Thuáº­t toÃ¡n chia khÃ¡ch hÃ ng thÃ nh 2 phe dá»±a trÃªn viá»‡c há» cÃ³ gáº¯n bÃ³ vá»›i ná»n táº£ng hay khÃ´ng.

Cá»¥m 0 (NhÃ³m Tiá»m nÄƒng/VÃ£ng lai):

Äáº·c Ä‘iá»ƒm: 100% KHÃ”NG Ä‘Äƒng kÃ½ Subscription.

ThÃ nh pháº§n: Há»—n há»£p cáº£ Nam vÃ  Ná»¯.

Ã nghÄ©a: ÄÃ¢y lÃ  nhÃ³m khÃ¡ch hÃ ng cáº§n target quáº£ng cÃ¡o Ä‘á»ƒ má»i chÃ o há» mua gÃ³i thÃ nh viÃªn.

Cá»¥m 1 (NhÃ³m Trung thÃ nh):

Äáº·c Ä‘iá»ƒm: Tá»· lá»‡ cÃ³ Subscription ráº¥t cao (~63%).

ThÃ nh pháº§n: Chá»§ yáº¿u lÃ  Nam giá»›i (trong láº§n cháº¡y K=2 cá»§a báº¡n, cá»¥m nÃ y bá»‹ lá»‡ch háº³n vá» Nam).

Ã nghÄ©a: NhÃ³m khÃ¡ch hÃ ng á»•n Ä‘á»‹nh, cáº§n chÃ­nh sÃ¡ch chÄƒm sÃ³c Ä‘á»ƒ giá»¯ chÃ¢n.

cÃ¡c chá»‰ sá»‘ nhÆ° Tuá»•i (Age),
Chi tiÃªu (Purchase Amount),
ÄÃ¡nh giÃ¡ (Rating)
cá»§a 2 nhÃ³m gáº§n nhÆ° y há»‡t nhau (44 tuá»•i, ~$60, 3.7 sao).Tuy nhiÃªn, sá»± khÃ¡c biá»‡t náº±m á»Ÿ h:NhÃ³m 0 (Cluster 0 - 1677 ngÆ°á»i):Giá»›i tÃ­nh: 100% lÃ  Nam (Male).Subscription: Tá»· lá»‡ cÃ³ Ä‘Äƒng kÃ½ thÃ nh viÃªn (Yes) chiáº¿m gáº§n 63%.

Táº¡m gá»i: "NhÃ³m Nam giá»›i & KhÃ¡ch hÃ ng thÃ¢n thiáº¿t".NhÃ³m 1 (Cluster 1 - 2223 ngÆ°á»i):Subscription: 100% KHÃ”NG Ä‘Äƒng kÃ½ (No).Giá»›i tÃ­nh: Há»—n há»£p cáº£ Nam vÃ  Ná»¯.$\rightarrow$ Táº¡m gá»i: "NhÃ³m KhÃ¡ch vÃ£ng lai (ChÆ°a Ä‘Äƒng kÃ½)".

# 1. Cháº¡y láº¡i KMeans vá»›i K=3
kmeans_k3 = KMeans(n_clusters=3, random_state=42, n_init=10)
labels_k3 = kmeans_k3.fit_predict(df_scaled)

# 2. GÃ¡n nhÃ£n vÃ o dá»¯ liá»‡u gá»‘c
df_k3 = df.copy()
df_k3['Cluster_K3'] = labels_k3

# --- BÆ¯á»šC Sá»¬A Lá»–I: CHUYá»‚N Äá»”I FREQUENCY SANG Sá» Äá»‚ TÃNH TRUNG BÃŒNH ---
freq_map = {
    'Weekly': 52,
    'Bi-Weekly': 26,
    'Fortnightly': 26,
    'Monthly': 12,
    'Quarterly': 4,
    'Every 3 Months': 4,
    'Annually': 1
}
# Chuyá»ƒn Ä‘á»•i cá»™t nÃ y sang sá»‘ (náº¿u gáº·p lá»—i thÃ¬ bá» qua báº±ng errors='coerce')
df_k3['Frequency of Purchases'] = df_k3['Frequency of Purchases'].map(freq_map)

# 3. Xem chÃ¢n dung 3 nhÃ³m má»›i
# BÃ¢y giá» toÃ n bá»™ cÃ¡c cá»™t trong list nÃ y Ä‘á»u Ä‘Ã£ lÃ  sá»‘
cols_to_analyze = ['Age', 'Purchase Amount (USD)', 'Review Rating', 'Previous Purchases', 'Frequency of Purchases']

profile_k3 = df_k3.groupby('Cluster_K3')[cols_to_analyze].mean()

# ThÃªm sá»‘ lÆ°á»£ng khÃ¡ch
profile_k3['Count'] = df_k3['Cluster_K3'].value_counts()

print("=== CHÃ‚N DUNG KHÃCH HÃ€NG KHI K=3 (Mean) ===")
display(profile_k3.style.background_gradient(cmap='YlOrRd'))

# 4. Kiá»ƒm tra láº¡i cÃ¡c biáº¿n Ä‘á»‹nh tÃ­nh
print("\n=== Tá»¶ Lá»† SUBSCRIPTION (K=3) ===")
print(pd.crosstab(df_k3['Cluster_K3'], df_k3['Subscription Status'], normalize='index') * 100)

print("\n=== Tá»¶ Lá»† GIá»šI TÃNH (K=3) ===")
print(pd.crosstab(df_k3['Cluster_K3'], df_k3['Gender'], normalize='index') * 100)

import matplotlib.pyplot as plt
import seaborn as sns

# Thiáº¿t láº­p lÆ°á»›i biá»ƒu Ä‘á»“ 2x2
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('So sÃ¡nh Äáº·c Ä‘iá»ƒm cá»§a 3 NhÃ³m KhÃ¡ch hÃ ng (K=3)', fontsize=16)

# 1. PhÃ¢n bá»‘ Giá»›i tÃ­nh theo tá»«ng cá»¥m
# NhÃ¬n vÃ o Ä‘Ã¢y sáº½ tháº¥y mÃ¡y tÃ¡ch Nam/Ná»¯ ráº¥t rÃµ
sns.countplot(ax=axes[0, 0], x='Cluster_K3', hue='Gender', data=df_k3, palette='pastel')
axes[0, 0].set_title('PhÃ¢n bá»‘ Giá»›i tÃ­nh trong tá»«ng Cá»¥m')
axes[0, 0].set_ylabel('Sá»‘ lÆ°á»£ng khÃ¡ch hÃ ng')

# 2. PhÃ¢n bá»‘ Subscription theo tá»«ng cá»¥m
sns.countplot(ax=axes[0, 1], x='Cluster_K3', hue='Subscription Status', data=df_k3, palette='Set2')
axes[0, 1].set_title('TÃ¬nh tráº¡ng ÄÄƒng kÃ½ (Subscription) trong tá»«ng Cá»¥m')
axes[0, 1].set_ylabel('Sá»‘ lÆ°á»£ng khÃ¡ch hÃ ng')

# 3. BIá»‚U Äá»’ CHI TIÃŠU (Boxplot)
# Má»¥c Ä‘Ã­ch: Chá»©ng minh ráº±ng má»©c chi tiÃªu giá»¯a cÃ¡c nhÃ³m KHÃ”NG khÃ¡c biá»‡t nhiá»u
sns.boxplot(ax=axes[1, 0], x='Cluster_K3', y='Purchase Amount (USD)', data=df_k3, palette='viridis')
axes[1, 0].set_title('Má»©c Chi tiÃªu trung bÃ¬nh (USD)')

# 4. BIá»‚U Äá»’ DANH Má»¤C MUA Sáº®M (Category)
# Xem thá»­ Ná»¯ (NhÃ³m 0) vÃ  Nam (NhÃ³m 1, 2) cÃ³ mua Ä‘á»“ khÃ¡c nhau khÃ´ng
sns.countplot(ax=axes[1, 1], x='Cluster_K3', hue='Category', data=df_k3, palette='muted')
axes[1, 1].set_title('Danh má»¥c sáº£n pháº©m hay mua theo Cá»¥m')
axes[1, 1].legend(loc='upper right', bbox_to_anchor=(1.25, 1))

plt.tight_layout()
plt.show()

3 nhÃ³m nÃ y Ä‘Æ°á»£c phÃ¢n loáº¡i hoÃ n toÃ n dá»±a trÃªn Ä‘áº·c Ä‘iá»ƒm nhÃ¢n kháº©u há»c chá»© khÃ´ng pháº£i hÃ nh vi chi tiÃªu.
============================================================================

Cluster 0: 100% lÃ  Ná»¯ (Female).

Cluster 1: 100% lÃ  Nam (Male) vÃ  KHÃ”NG Ä‘Äƒng kÃ½ Subscription.

Cluster 2: 100% lÃ  Nam (Male) vÃ  CÃ“ (hoáº·c tá»«ng cÃ³) Ä‘Äƒng kÃ½ Subscription (tá»· lá»‡ Yes cao ~63%).

CÃ¡c chá»‰ sá»‘ Chi tiÃªu, Tuá»•i, ÄÃ¡nh giÃ¡ váº«n "pháº³ng lÃ¬" (ngang nhau). Äiá»u nÃ y kháº³ng Ä‘á»‹nh bá»™ dá»¯ liá»‡u nÃ y ráº¥t khÃ³ Ä‘á»ƒ phÃ¢n cá»¥m theo hÃ nh vi (Behavior), mÃ  mÃ¡y chá»‰ Ä‘ang gom nhÃ³m theo Ä‘áº·c tÃ­nh (Attribute).

Vá»›i K=3: PhÃ¢n loáº¡i theo "Giá»›i tÃ­nh & ÄÄƒng kÃ½" (Chi tiáº¿t hÆ¡n)
===============================================================================
Khi Ã©p chia thÃ nh 3 nhÃ³m, thuáº­t toÃ¡n tÃ¡ch dá»¯ liá»‡u ká»¹ hÆ¡n dá»±a trÃªn Giá»›i tÃ­nh.

Cá»¥m 0 (Ná»¯ giá»›i - ChÆ°a khai thÃ¡c):

Äáº·c Ä‘iá»ƒm: 100% lÃ  Ná»¯.

Subscription: 100% KHÃ”NG Ä‘Äƒng kÃ½.

Insight Ä‘áº¯t giÃ¡: Táº¡i sao khÃ¡ch hÃ ng Ná»¯ trong táº­p dá»¯ liá»‡u nÃ y hoÃ n toÃ n khÃ´ng quan tÃ¢m Ä‘áº¿n gÃ³i Subscription? -> ÄÃ¢y lÃ  váº¥n Ä‘á» kinh doanh lá»›n cáº§n giáº£i quyáº¿t.

Cá»¥m 1 (Nam giá»›i - VÃ£ng lai):

Äáº·c Ä‘iá»ƒm: 100% lÃ  Nam.

Subscription: 100% KHÃ”NG Ä‘Äƒng kÃ½.

Cá»¥m 2 (Nam giá»›i - VIP):

Äáº·c Ä‘iá»ƒm: 100% lÃ  Nam.

Subscription: Äa sá»‘ CÃ“ Ä‘Äƒng kÃ½ (~63%).

Káº¿t luáº­n
==========================================

"Máº·c dÃ¹ má»©c chi tiÃªu (Purchase Amount) giá»¯a cÃ¡c nhÃ³m lÃ  tÆ°Æ¡ng Ä‘á»“ng, nhÆ°ng thuáº­t toÃ¡n K-Means (vá»›i K=3) Ä‘Ã£ phÃ¡t hiá»‡n ra má»™t Insight quan trá»ng vá» cáº¥u trÃºc khÃ¡ch hÃ ng: Sá»± váº¯ng bÃ³ng hoÃ n toÃ n cá»§a khÃ¡ch hÃ ng Ná»¯ trong nhÃ³m cÃ³ Subscription. Äiá»u nÃ y gá»£i Ã½ doanh nghiá»‡p cáº§n thiáº¿t káº¿ láº¡i gÃ³i Subscription Ä‘á»ƒ háº¥p dáº«n phÃ¡i ná»¯ hÆ¡n."

#5.Training

##Chuáº©n bá»‹

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc

# --- 1. CHUáº¨N Bá»Š Dá»® LIá»†U ---
# Äáº£m báº£o dÃ¹ng df_clean (dá»¯ liá»‡u Ä‘Ã£ chuyá»ƒn sang sá»‘ toÃ n bá»™)
# Biáº¿n má»¥c tiÃªu (Target)
y = df_clean['Subscription Status']

# Biáº¿n Ä‘áº§u vÃ o (Features) - Loáº¡i bá» cá»™t Target
X = df_clean.drop('Subscription Status', axis=1)

# Chia dá»¯ liá»‡u: 80% Train - 20% Test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Chuáº©n hÃ³a dá»¯ liá»‡u (Quan trá»ng cho Logistic Regression vÃ  KNN)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# --- 2. VIáº¾T HÃ€M ÄÃNH GIÃ & TRá»°C QUAN HÃ“A ---
def danh_gia_mo_hinh(model, model_name, X_test_data, y_test_data):
    # Dá»± Ä‘oÃ¡n
    y_pred = model.predict(X_test_data)
    y_prob = model.predict_proba(X_test_data)[:, 1] # Láº¥y xÃ¡c suáº¥t lá»›p 1 Ä‘á»ƒ váº½ ROC

    # 1. In chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡
    acc = accuracy_score(y_test_data, y_pred)
    print(f"\n{'='*20} {model_name.upper()} {'='*20}")
    print(f"Äá»™ chÃ­nh xÃ¡c (Accuracy): {acc:.2%}")
    print("\nBÃ¡o cÃ¡o chi tiáº¿t:")
    print(classification_report(y_test_data, y_pred))

    # Thiáº¿t láº­p khung váº½ 2 biá»ƒu Ä‘á»“
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # 2. Váº½ Confusion Matrix (Ma tráº­n nháº§m láº«n)
    cm = confusion_matrix(y_test_data, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0], cbar=False)
    axes[0].set_title(f'Confusion Matrix - {model_name}')
    axes[0].set_xlabel('Dá»± Ä‘oÃ¡n (Predicted)')
    axes[0].set_ylabel('Thá»±c táº¿ (Actual)')
    axes[0].set_xticklabels(['No (0)', 'Yes (1)'])
    axes[0].set_yticklabels(['No (0)', 'Yes (1)'])

    # 3. Váº½ Ä‘Æ°á»ng cong ROC (ROC Curve)
    fpr, tpr, thresholds = roc_curve(y_test_data, y_prob)
    roc_auc = auc(fpr, tpr)

    axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
    axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    axes[1].set_xlim([0.0, 1.0])
    axes[1].set_ylim([0.0, 1.05])
    axes[1].set_xlabel('False Positive Rate')
    axes[1].set_ylabel('True Positive Rate')
    axes[1].set_title(f'ROC Curve - {model_name}')
    axes[1].legend(loc="lower right")

    plt.tight_layout()
    plt.show()

    return acc

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

# Danh sÃ¡ch lÆ°u káº¿t quáº£ Ä‘á»ƒ so sÃ¡nh sau cÃ¹ng
ket_qua = {}

##MÃ” HÃŒNH 1: LOGISTIC REGRESSION

lr_model = LogisticRegression(random_state=42)
lr_model.fit(X_train_scaled, y_train)
ket_qua['Logistic Regression'] = danh_gia_mo_hinh(lr_model, "Logistic Regression", X_test_scaled, y_test)

# Äá»™ chÃ­nh xÃ¡c (Accuracy): 82.56%.

# ÄÃ¢y lÃ  má»™t má»©c Ä‘á»™ chÃ­nh xÃ¡c khÃ¡ tá»‘t (mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n Ä‘Ãºng hÆ¡n 8/10 trÆ°á»ng há»£p). Tuy nhiÃªn, Ä‘á»™ chÃ­nh xÃ¡c nÃ y bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi sá»± máº¥t cÃ¢n báº±ng dá»¯ liá»‡u (lá»›p 0 nhiá»u gáº¥p Ä‘Ã´i lá»›p 1), nÃªn cáº§n nhÃ¬n sÃ¢u hÆ¡n vÃ o cÃ¡c chá»‰ sá»‘ khÃ¡c.

# AUC Score: 0.87.

# ÄÆ°á»ng cong ROC vÃ  diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong (AUC = 0.87) cho tháº¥y kháº£ nÄƒng phÃ¢n loáº¡i cá»§a mÃ´ hÃ¬nh lÃ  ráº¥t tá»‘t. MÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng phÃ¢n biá»‡t rÃµ rÃ ng giá»¯a hai lá»›p (Positive vÃ  Negative).

# PhÃ¢n tÃ­ch chi tiáº¿t qua Confusion Matrix (Ma tráº­n nháº§m láº«n)
# Äiá»ƒm Ä‘áº·c biá»‡t nháº¥t cá»§a mÃ´ hÃ¬nh nÃ y náº±m á»Ÿ sá»± phÃ¢n bá»‘ cÃ¡c giÃ¡ trá»‹ dá»± Ä‘oÃ¡n:

# True Negative (TN): 422. Dá»± Ä‘oÃ¡n Ä‘Ãºng 422 trÆ°á»ng há»£p lÃ  lá»›p 0 (No).

# False Positive (FP): 136. Dá»± Ä‘oÃ¡n sai 136 trÆ°á»ng há»£p lÃ  lá»›p 1 (Yes) trong khi thá»±c táº¿ lÃ  0.

# False Negative (FN): 0. ÄÃ¢y lÃ  con sá»‘ cá»±c ká»³ áº¥n tÆ°á»£ng. MÃ´ hÃ¬nh khÃ´ng bá» sÃ³t báº¥t ká»³ trÆ°á»ng há»£p lá»›p 1 (Yes) nÃ o.

# True Positive (TP): 222. Dá»± Ä‘oÃ¡n Ä‘Ãºng toÃ n bá»™ 222 trÆ°á»ng há»£p thá»±c táº¿ lÃ  lá»›p 1.

# ÄÃ¡nh giÃ¡ Precision vÃ  Recall (Quan trá»ng)
# MÃ´ hÃ¬nh thá»ƒ hiá»‡n sá»± Ä‘Ã¡nh Ä‘á»•i rÃµ rá»‡t (trade-off) giá»¯a Ä‘á»™ chÃ­nh xÃ¡c vÃ  Ä‘á»™ bao phá»§ cho tá»«ng lá»›p:

# Äá»‘i vá»›i Lá»›p 1 (Yes - Positive): Tá»‘i Æ°u hÃ³a Recall

# Recall = 1.00 (Tuyá»‡t Ä‘á»‘i): MÃ´ hÃ¬nh báº¯t Ä‘Æ°á»£c 100% cÃ¡c trÆ°á»ng há»£p Positive. Náº¿u bÃ i toÃ¡n cá»§a báº¡n lÃ  dá»± Ä‘oÃ¡n khÃ¡ch hÃ ng rá»i bá» (Churn) hoáº·c phÃ¡t hiá»‡n gian láº­n, Ä‘Ã¢y lÃ  mÃ´ hÃ¬nh lÃ½ tÆ°á»Ÿng vÃ¬ nÃ³ khÃ´ng bá» sÃ³t ai.

# Precision = 0.62 (Trung bÃ¬nh): Há»‡ quáº£ cá»§a viá»‡c báº¯t háº¿t lÃ  "báº¯t nháº§m". Trong sá»‘ nhá»¯ng trÆ°á»ng há»£p mÃ´ hÃ¬nh Ä‘oÃ¡n lÃ  "Yes", chá»‰ cÃ³ 62% lÃ  Ä‘Ãºng, cÃ²n láº¡i lÃ  bÃ¡o Ä‘á»™ng giáº£ (False Alarm).

# Äá»‘i vá»›i Lá»›p 0 (No - Negative): Tá»‘i Æ°u hÃ³a Precision

# Precision = 1.00 (Tuyá»‡t Ä‘á»‘i): Khi mÃ´ hÃ¬nh phÃ¡n Ä‘oÃ¡n lÃ  "No", nÃ³ cháº¯c cháº¯n Ä‘Ãºng 100%. KhÃ´ng bao giá» cÃ³ chuyá»‡n mÃ´ hÃ¬nh nÃ³i "No" mÃ  thá»±c táº¿ láº¡i lÃ  "Yes".

# Recall = 0.76: Tuy nhiÃªn, nÃ³ láº¡i bá» lá»¡ khÃ¡ nhiá»u trÆ°á»ng há»£p "No" thá»±c táº¿ (bá»‹ gÃ¡n nháº§m sang "Yes").

# Káº¿t luáº­n vá» hÃ nh vi cá»§a mÃ´ hÃ¬nh
# MÃ´ hÃ¬nh nÃ y Ä‘ang hoáº¡t Ä‘á»™ng theo xu hÆ°á»›ng "ThÃ  báº¯t nháº§m cÃ²n hÆ¡n bá» sÃ³t" Ä‘á»‘i vá»›i Lá»›p 1 (Yes).

# Äiá»ƒm máº¡nh: Äá»™ tin cáº­y cá»±c cao khi dá»± Ä‘oÃ¡n "No" vÃ  Ä‘á»™ bao phá»§ tuyá»‡t Ä‘á»‘i khi tÃ¬m kiáº¿m "Yes".

# Äiá»ƒm yáº¿u: Tá»· lá»‡ bÃ¡o Ä‘á»™ng giáº£ (False Positive) khÃ¡ cao Ä‘á»‘i vá»›i Lá»›p 1.

# á»¨ng dá»¥ng thá»±c táº¿:

# Náº¿u "Yes" lÃ  "KhÃ¡ch hÃ ng mua hÃ ng": MÃ´ hÃ¬nh nÃ y ráº¥t tá»‘t Ä‘á»ƒ lá»c ra danh sÃ¡ch khÃ¡ch hÃ ng tiá»m nÄƒng rá»™ng (khÃ´ng bá» sÃ³t ai), cháº¥p nháº­n viá»‡c marketing nháº§m cho má»™t sá»‘ ngÆ°á»i khÃ´ng mua.

# Náº¿u "Yes" lÃ  "Spam email": MÃ´ hÃ¬nh nÃ y sáº½ tá»‡, vÃ¬ nÃ³ sáº½ cháº·n nháº§m nhiá»u email quan trá»ng (False Positive cao) vÃ o há»™p thÆ° Spam.

##MÃ” HÃŒNH 2: DECISION TREE

dt_model = DecisionTreeClassifier(random_state=42, max_depth=5) # Giá»›i háº¡n Ä‘á»™ sÃ¢u Ä‘á»ƒ trÃ¡nh overfitting
dt_model.fit(X_train, y_train) # CÃ¢y quyáº¿t Ä‘á»‹nh khÃ´ng cáº§n scaled data
ket_qua['Decision Tree'] = danh_gia_mo_hinh(dt_model, "Decision Tree", X_test, y_test)

# Äá»™ chÃ­nh xÃ¡c (Accuracy): 82.56%

# MÃ´ hÃ¬nh phÃ¢n loáº¡i Ä‘Ãºng hÆ¡n 82% tá»•ng sá»‘ máº«u. ÄÃ¢y lÃ  má»©c hiá»‡u suáº¥t khÃ¡ tá»‘t, cho tháº¥y mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c quy luáº­t tá»« dá»¯ liá»‡u.

# ROC - AUC Score: 0.89

# Chá»‰ sá»‘ AUC xáº¥p xá»‰ 0.9 lÃ  má»™t káº¿t quáº£ ráº¥t cao. ÄÆ°á»ng cong ROC mÃ u cam Ã´m sÃ¡t gÃ³c trÃªn bÃªn trÃ¡i cho tháº¥y kháº£ nÄƒng phÃ¢n tÃ¡ch giá»¯a hai lá»›p (0 vÃ  1) cá»§a mÃ´ hÃ¬nh lÃ  ráº¥t máº¡nh máº½, tá»‘t hÆ¡n nhiá»u so vá»›i Ä‘oÃ¡n ngáº«u nhiÃªn (Ä‘Æ°á»ng nÃ©t Ä‘á»©t).

# 2. PhÃ¢n tÃ­ch chi tiáº¿t tá»«ng lá»›p (Classification Report)
# Lá»›p 0 (NhÃ£n 'No' - Chiáº¿m Ä‘a sá»‘ 558 máº«u):

# Precision (Äá»™ chÃ­nh xÃ¡c): 0.99

# Gáº§n nhÆ° tuyá»‡t Ä‘á»‘i. Khi mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n má»™t máº«u lÃ  Lá»›p 0, xÃ¡c suáº¥t Ä‘Ãºng lÃªn tá»›i 99%. Ráº¥t Ã­t khi mÃ´ hÃ¬nh nháº§m láº«n gÃ¡n nhÃ£n Lá»›p 0 cho má»™t máº«u thá»±c táº¿ lÃ  Lá»›p 1.

# Recall (Äá»™ nháº¡y): 0.77

# MÃ´ hÃ¬nh chá»‰ tÃ¬m láº¡i Ä‘Æ°á»£c 77% sá»‘ lÆ°á»£ng máº«u Lá»›p 0 thá»±c táº¿. CÃ²n khoáº£ng 23% máº«u Lá»›p 0 bá»‹ mÃ´ hÃ¬nh bá» sÃ³t (gÃ¡n nháº§m sang Lá»›p 1).

# F1-Score: 0.86 -> Káº¿t quáº£ tá»•ng há»£p tá»‘t.

# Lá»›p 1 (NhÃ£n 'Yes' - Chiáº¿m thiá»ƒu sá»‘ 222 máº«u):

# Precision: 0.62

# ÄÃ¢y lÃ  Ä‘iá»ƒm yáº¿u nháº¥t cá»§a mÃ´ hÃ¬nh. Trong sá»‘ cÃ¡c máº«u Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  Lá»›p 1, chá»‰ cÃ³ 62% lÃ  chÃ­nh xÃ¡c. Tá»©c lÃ  cÃ³ má»™t lÆ°á»£ng lá»›n "bÃ¡o Ä‘á»™ng giáº£" (False Positives).

# Recall: 0.98

# Ráº¥t áº¥n tÆ°á»£ng. MÃ´ hÃ¬nh tÃ¬m ra Ä‘Æ°á»£c 98% (217/222) sá»‘ lÆ°á»£ng máº«u Lá»›p 1 thá»±c táº¿. NÃ³ gáº§n nhÆ° khÃ´ng bá» sÃ³t cÃ¡c trÆ°á»ng há»£p quan trá»ng cá»§a Lá»›p 1.

# 3. PhÃ¢n tÃ­ch lá»—i qua Confusion Matrix
# Dá»± Ä‘oÃ¡n Ä‘Ãºng (ÄÆ°á»ng chÃ©o chÃ­nh):

# TN (True Negative): 427. Dá»± Ä‘oÃ¡n Ä‘Ãºng 427 trÆ°á»ng há»£p Lá»›p 0.

# TP (True Positive): 217. Dá»± Ä‘oÃ¡n Ä‘Ãºng 217 trÆ°á»ng há»£p Lá»›p 1.

# Dá»± Ä‘oÃ¡n sai (ÄÆ°á»ng chÃ©o phá»¥):

# FP (False Positive): 131. CÃ³ 131 máº«u thá»±c táº¿ lÃ  Lá»›p 0 nhÆ°ng bá»‹ nháº§m thÃ nh Lá»›p 1. ÄÃ¢y chÃ­nh lÃ  nguyÃªn nhÃ¢n lÃ m giáº£m Precision cá»§a Lá»›p 1 xuá»‘ng 0.62.

# FN (False Negative): 5. Chá»‰ cÃ³ 5 máº«u thá»±c táº¿ lÃ  Lá»›p 1 bá»‹ bá» sÃ³t (nháº§m thÃ nh Lá»›p 0). Con sá»‘ nÃ y ráº¥t nhá», giáº£i thÃ­ch cho Recall cao (0.98) cá»§a Lá»›p 1.

# Káº¿t luáº­n
# MÃ´ hÃ¬nh Decision Tree nÃ y cÃ³ Ä‘áº·c Ä‘iá»ƒm hoáº¡t Ä‘á»™ng ráº¥t rÃµ rÃ ng:

# Æ¯u tiÃªn "Báº¯t nháº§m cÃ²n hÆ¡n bá» sÃ³t" Ä‘á»‘i vá»›i Lá»›p 1: NÃ³ cá»±c ká»³ nháº¡y bÃ©n trong viá»‡c phÃ¡t hiá»‡n Lá»›p 1 (Recall 0.98), cháº¥p nháº­n viá»‡c dá»± bÃ¡o sai má»™t lÆ°á»£ng Ä‘Ã¡ng ká»ƒ cÃ¡c máº«u Lá»›p 0 thÃ nh Lá»›p 1 (FP = 131).

# Äá»™ tin cáº­y cá»±c cao khi dá»± bÃ¡o Lá»›p 0: Náº¿u mÃ´ hÃ¬nh phÃ¡n Ä‘oÃ¡n lÃ  "KhÃ´ng" (Lá»›p 0), cÃ³ thá»ƒ tin tÆ°á»Ÿng gáº§n nhÆ° tuyá»‡t Ä‘á»‘i (Precision 0.99).

##MÃ” HÃŒNH 3: RANDOM FOREST

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
ket_qua['Random Forest'] = danh_gia_mo_hinh(rf_model, "Random Forest", X_test, y_test)

# Hiá»‡u suáº¥t tá»•ng thá»ƒ (Overall Performance)
# Äá»™ chÃ­nh xÃ¡c (Accuracy): 81.67%

# MÃ´ hÃ¬nh phÃ¢n loáº¡i Ä‘Ãºng gáº§n 82% trÃªn tá»•ng sá»‘ máº«u thá»­ nghiá»‡m. ÄÃ¢y lÃ  má»©c Ä‘á»™ chÃ­nh xÃ¡c khÃ¡ tá»‘t.

# ROC - AUC Score: 0.89

# Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong (AUC) Ä‘áº¡t 0.89 lÃ  má»™t chá»‰ sá»‘ ráº¥t áº¥n tÆ°á»£ng. ÄÆ°á»ng cong mÃ u cam vÆ°Æ¡n cao nhanh chÃ³ng vá» phÃ­a gÃ³c trÃ¡i trÃªn cho tháº¥y mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng phÃ¢n biá»‡t (discrimination) ráº¥t tá»‘t giá»¯a hai lá»›p Yes vÃ  No.

# 2. PhÃ¢n tÃ­ch chi tiáº¿t tá»«ng lá»›p
# Lá»›p 1 (NhÃ£n 'Yes' - Thiá»ƒu sá»‘, quan trá»ng):

# Recall (Äá»™ nháº¡y): 0.92

# ÄÃ¢y lÃ  Ä‘iá»ƒm máº¡nh nháº¥t cá»§a mÃ´ hÃ¬nh. Trong sá»‘ 222 trÆ°á»ng há»£p thá»±c táº¿ lÃ  'Yes', mÃ´ hÃ¬nh Ä‘Ã£ phÃ¡t hiá»‡n Ä‘Ãºng Ä‘Æ°á»£c 92% (204 trÆ°á»ng há»£p). Tá»· lá»‡ bá» sÃ³t (False Negative) ráº¥t tháº¥p.

# Precision (Äá»™ chÃ­nh xÃ¡c): 0.62

# TÆ°Æ¡ng tá»± cÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i máº¥t cÃ¢n báº±ng, Ä‘iá»ƒm yáº¿u náº±m á»Ÿ Ä‘Ã¢y. Khi mÃ´ hÃ¬nh dá»± bÃ¡o lÃ  'Yes', chá»‰ cÃ³ 62% lÃ  Ä‘Ãºng. Äiá»u nÃ y Ä‘á»“ng nghÄ©a vá»›i viá»‡c cÃ³ khÃ¡ nhiá»u trÆ°á»ng há»£p 'No' bá»‹ nháº§m thÃ nh 'Yes' (BÃ¡o Ä‘á»™ng giáº£).

# Lá»›p 0 (NhÃ£n 'No' - Äa sá»‘):

# Precision: 0.96

# Äá»™ tin cáº­y cá»±c cao. Khi mÃ´ hÃ¬nh nÃ³i "No", xÃ¡c suáº¥t Ä‘Ãºng lÃªn tá»›i 96%. Ráº¥t hiáº¿m khi mÃ´ hÃ¬nh dá»± bÃ¡o "No" mÃ  thá»±c táº¿ láº¡i lÃ  "Yes".

# Recall: 0.78

# MÃ´ hÃ¬nh chá»‰ bao phá»§ Ä‘Æ°á»£c 78% sá»‘ lÆ°á»£ng máº«u 'No' thá»±c táº¿. 22% cÃ²n láº¡i Ä‘Ã£ bá»‹ dá»± Ä‘oÃ¡n nháº§m sang 'Yes'.

# 3. PhÃ¢n tÃ­ch lá»—i qua Confusion Matrix
# Dá»± Ä‘oÃ¡n Ä‘Ãºng (ÄÆ°á»ng chÃ©o mÃ u Ä‘áº­m):

# True Negative (TN): 433. Dá»± Ä‘oÃ¡n Ä‘Ãºng 433 máº«u lÃ  'No'.

# True Positive (TP): 204. Dá»± Ä‘oÃ¡n Ä‘Ãºng 204 máº«u lÃ  'Yes'.

# Dá»± Ä‘oÃ¡n sai (ÄÆ°á»ng chÃ©o mÃ u nháº¡t):

# False Positive (FP): 125. CÃ³ 125 máº«u thá»±c táº¿ lÃ  'No' nhÆ°ng bá»‹ mÃ¡y bÃ¡o nháº§m lÃ  'Yes'. ÄÃ¢y lÃ  nguyÃªn nhÃ¢n kÃ©o Precision cá»§a lá»›p 1 xuá»‘ng tháº¥p.

# False Negative (FN): 18. Chá»‰ cÃ³ 18 máº«u thá»±c táº¿ lÃ  'Yes' bá»‹ bá» sÃ³t (mÃ¡y bÃ¡o lÃ  'No'). Con sá»‘ nÃ y nhá», chá»©ng tá» rá»§i ro bá» sÃ³t Ä‘á»‘i tÆ°á»£ng má»¥c tiÃªu lÃ  tháº¥p.

# Káº¿t luáº­n vá» hÃ nh vi mÃ´ hÃ¬nh
# MÃ´ hÃ¬nh Random Forest nÃ y thá»ƒ hiá»‡n má»™t chiáº¿n lÆ°á»£c "Tháº­n trá»ng vá»›i viá»‡c bá» sÃ³t":

##MÃ” HÃŒNH 4: K-NEAREST NEIGHBORS (KNN)

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train_scaled, y_train)
ket_qua['KNN'] = danh_gia_mo_hinh(knn_model, "K-Nearest Neighbors", X_test_scaled, y_test)

# Hiá»‡u suáº¥t tá»•ng thá»ƒ (Overall Performance)
# Äá»™ chÃ­nh xÃ¡c (Accuracy): 81.03%

# MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n Ä‘Ãºng khoáº£ng 81% trÃªn tá»•ng sá»‘ dá»¯ liá»‡u. Máº·c dÃ¹ Ä‘Ã¢y lÃ  má»™t con sá»‘ khÃ¡ tá»‘t, nhÆ°ng nÃ³ tháº¥p hÆ¡n má»™t chÃºt so vá»›i cÃ¡c mÃ´ hÃ¬nh trÆ°á»›c (nhÆ° Decision Tree hay Logistic Regression).

# ROC - AUC Score: 0.87

# Chá»‰ sá»‘ AUC = 0.87 cho tháº¥y mÃ´ hÃ¬nh KNN váº«n cÃ³ kháº£ nÄƒng phÃ¢n tÃ¡ch hai lá»›p tá»‘t. Tuy nhiÃªn, Ä‘Æ°á»ng cong ROC cÃ³ dáº¡ng gáº¥p khÃºc (gÃ£y khÃºc) thay vÃ¬ cong mÆ°á»£t mÃ , Ä‘Ã¢y lÃ  Ä‘áº·c trÆ°ng thÆ°á»ng tháº¥y cá»§a KNN do tÃ­nh cháº¥t dá»±a trÃªn "lÃ¡ng giá»ng" rá»i ráº¡c cá»§a nÃ³.

# PhÃ¢n tÃ­ch chi tiáº¿t tá»«ng lá»›p (Classification Report)
# Lá»›p 0 (NhÃ£n 'No' - Äa sá»‘):

# Precision: 0.91

# Khi mÃ´ hÃ¬nh dá»± bÃ¡o lÃ  'No', Ä‘á»™ tin cáº­y Ä‘áº¡t 91%. ÄÃ¢y lÃ  má»©c cao, nhÆ°ng khÃ´ng tuyá»‡t Ä‘á»‘i nhÆ° Decision Tree (0.99) hay Logistic Regression (1.00). Tá»©c lÃ  váº«n cÃ³ xÃ¡c suáº¥t nhá» (9%) mÃ´ hÃ¬nh nÃ³i 'No' nhÆ°ng thá»±c táº¿ lÃ  'Yes'.

# Recall: 0.81

# MÃ´ hÃ¬nh nháº­n diá»‡n láº¡i Ä‘Æ°á»£c 81% sá»‘ lÆ°á»£ng máº«u 'No' thá»±c táº¿. NÃ³ bá» sÃ³t khoáº£ng 19% (gÃ¡n nháº§m sang 'Yes').

# Lá»›p 1 (NhÃ£n 'Yes' - Thiá»ƒu sá»‘):

# Precision: 0.63

# TÆ°Æ¡ng tá»± cÃ¡c mÃ´ hÃ¬nh khÃ¡c, Ä‘á»™ chÃ­nh xÃ¡c khi dá»± bÃ¡o 'Yes' chá»‰ á»Ÿ má»©c trung bÃ¬nh. CÃ³ nhiá»u bÃ¡o Ä‘á»™ng giáº£ (False Positives).

# Recall: 0.81

# ÄÃ¢y lÃ  Ä‘iá»ƒm Ä‘Ã¡ng chÃº Ã½ nháº¥t. Recall cá»§a lá»›p 1 chá»‰ Ä‘áº¡t 81%. So vá»›i Decision Tree (98%) hay Random Forest (92%), mÃ´ hÃ¬nh KNN kÃ©m nháº¡y hÆ¡n trong viá»‡c phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng má»¥c tiÃªu. NÃ³ bá» sÃ³t tá»›i 19% sá»‘ lÆ°á»£ng trÆ°á»ng há»£p 'Yes'.

# PhÃ¢n tÃ­ch lá»—i qua Confusion Matrix
# Äiá»ƒm cÃ¢n báº±ng hÆ¡n:

# TN (True Negative): 453. MÃ´ hÃ¬nh KNN dá»± Ä‘oÃ¡n Ä‘Ãºng lá»›p 'No' nhiá»u hÆ¡n so vá»›i cÃ¡c mÃ´ hÃ¬nh trÆ°á»›c (thÆ°á»ng chá»‰ ~420-430). Äiá»u nÃ y cho tháº¥y KNN "tháº­n trá»ng" hÆ¡n vÃ  Ã­t gÃ¡n nhÃ£n 'Yes' bá»«a bÃ£i hÆ¡n.

# TP (True Positive): 179. Sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng lá»›p 'Yes' tháº¥p hÆ¡n háº³n (chá»‰ 179 so vá»›i >200 cá»§a cÃ¡c mÃ´ hÃ¬nh khÃ¡c).

# Lá»—i phÃ¢n loáº¡i:

# FP (False Positive): 105. Sá»‘ lÆ°á»£ng bÃ¡o Ä‘á»™ng giáº£ tháº¥p hÆ¡n. ÄÃ¢y lÃ  Æ°u Ä‘iá»ƒm: KNN Ã­t lÃ m phiá»n ngÆ°á»i dÃ¹ng vá»›i cÃ¡c dá»± bÃ¡o sai vá» 'Yes' hÆ¡n.

# FN (False Negative): 43. Sá»‘ lÆ°á»£ng bá» sÃ³t Ä‘á»‘i tÆ°á»£ng má»¥c tiÃªu cao hÆ¡n Ä‘Ã¡ng ká»ƒ (43 trÆ°á»ng há»£p so vá»›i <20 á»Ÿ cÃ¡c mÃ´ hÃ¬nh khÃ¡c).

# Káº¿t luáº­n vá» hÃ nh vi mÃ´ hÃ¬nh KNN
# MÃ´ hÃ¬nh KNN nÃ y thá»ƒ hiá»‡n sá»± "Trung dung vÃ  CÃ¢n báº±ng" hÆ¡n:

# Ãt bÃ¡o Ä‘á»™ng giáº£ hÆ¡n (Better Precision for No)

##So sÃ¡nh

# Táº¡o báº£ng so sÃ¡nh
df_compare = pd.DataFrame(list(ket_qua.items()), columns=['MÃ´ hÃ¬nh', 'Äá»™ chÃ­nh xÃ¡c (Accuracy)'])
df_compare = df_compare.sort_values(by='Äá»™ chÃ­nh xÃ¡c (Accuracy)', ascending=False)

# Váº½ biá»ƒu Ä‘á»“ so sÃ¡nh
plt.figure(figsize=(10, 6))
sns.barplot(x='Äá»™ chÃ­nh xÃ¡c (Accuracy)', y='MÃ´ hÃ¬nh', data=df_compare, palette='viridis')
plt.title('SO SÃNH Äá»˜ CHÃNH XÃC CÃC MÃ” HÃŒNH', fontsize=14)
plt.xlim(0, 1.0) # Trá»¥c X tá»« 0 Ä‘áº¿n 100%
for index, value in enumerate(df_compare['Äá»™ chÃ­nh xÃ¡c (Accuracy)']):
    plt.text(value + 0.01, index, f'{value:.2%}', va='center', fontweight='bold')
plt.show()

#Inference

giáº£ Ä‘á»‹nh Ä‘á»‘i láº­p nhau Ä‘á»ƒ xem Model suy luáº­n tháº¿ nÃ o:

NhÃ¢n váº­t A Tiá»m NÄƒng: Nam, ÄÃ¡nh giÃ¡ 5 sao, Mua hÃ ng tuáº§n, Chi tiÃªu cao. $\rightarrow$ Ká»³ vá»ng: Model Ä‘oÃ¡n lÃ  YES.NhÃ¢n váº­t B (Ms. KhÃ³ TÃ­nh): Ná»¯, ÄÃ¡nh giÃ¡ 2 sao, Mua hÃ ng nÄƒm, Chi tiÃªu tháº¥p. $\rightarrow$ Ká»³ vá»ng: Model Ä‘oÃ¡n lÃ  NO.

import pandas as pd

# 1. Táº O Dá»® LIá»†U GIáº¢ Äá»ŠNH (TEST CASES)
# LÆ°u Ã½: CÃ¡c giÃ¡ trá»‹ sá»‘ pháº£i khá»›p vá»›i quy Æ°á»›c Encoding á»Ÿ bÆ°á»›c tiá»n xá»­ lÃ½
# Gender: 1=Male, 0=Female
# Frequency: 52=Weekly, 1=Annually
# Subscription Status lÃ  cÃ¡i ta cáº§n dá»± Ä‘oÃ¡n

case_studies = pd.DataFrame({
    'Age':                    [35, 20],            # A: TrÆ°á»Ÿng thÃ nh vs B: Tráº»
    'Gender':                 [1, 0],              # A: Nam (1) vs B: Ná»¯ (0) - Dá»±a trÃªn insight K-Means
    'Item Purchased':         [5, 5],              # Giá»‘ng nhau
    'Category':               [1, 1],              # Giá»‘ng nhau
    'Purchase Amount (USD)':  [95, 25],            # A: Mua nhiá»u vs B: Mua Ã­t
    'Location':               [10, 10],            # Giá»‘ng nhau
    'Size':                   [2, 1],              # M vs S
    'Color':                  [5, 5],              # Giá»‘ng nhau
    'Season':                 [3, 3],              # Giá»‘ng nhau
    'Review Rating':          [5.0, 2.5],          # A: Khen háº¿t lá»i vs B: ChÃª
    'Shipping Type':          [1, 1],
    'Discount Applied':       [1, 0],              # A: CÃ³ mÃ£ vs B: KhÃ´ng
    'Promo Code Used':        [1, 0],
    'Previous Purchases':     [40, 2],             # A: KhÃ¡ch quen vs B: KhÃ¡ch má»›i
    'Payment Method':         [2, 2],
    'Frequency of Purchases': [52, 1]              # A: HÃ ng tuáº§n vs B: HÃ ng nÄƒm
})

# Äáº·t tÃªn cho index Ä‘á»ƒ dá»… nhÃ¬n
case_studies.index = ['Mr. Tiá»m NÄƒng (Logic Tá»‘t)', 'Ms. KhÃ³ TÃ­nh (Logic Xáº¥u)']

print("=== Há»’ SÆ  2 KHÃCH HÃ€NG Cáº¦N SUY LUáº¬N ===")
display(case_studies)

# 2. CHUáº¨N HÃ“A Dá»® LIá»†U (SCALING)
# Model há»c trÃªn dá»¯ liá»‡u Ä‘Ã£ scale, nÃªn dá»¯ liá»‡u má»›i cÅ©ng pháº£i scale y há»‡t
case_studies_scaled = scaler.transform(case_studies)

# 3. THá»°C HIá»†N SUY LUáº¬N (INFERENCE) Vá»šI RANDOM FOREST
print("\n=== Káº¾T QUáº¢ SUY LUáº¬N Cá»¦A MÃY (AI INFERENCE) ===")

preds = rf_model.predict(case_studies_scaled)
probs = rf_model.predict_proba(case_studies_scaled)

for i, name in enumerate(case_studies.index):
    ket_qua = "CÃ“ ÄÄƒng kÃ½ (Yes)" if preds[i] == 1 else "KHÃ”NG ÄÄƒng kÃ½ (No)"
    do_tin_cay = probs[i][preds[i]]

    print(f"KhÃ¡ch hÃ ng: {name}")
    print(f" -> MÃ¡y suy luáº­n: {ket_qua}")
    print(f" -> Äá»™ tin cáº­y (Confidence): {do_tin_cay:.2%}")
    print("-" * 30)

Káº¿t quáº£ dá»± Ä‘oÃ¡n:

Ms. KhÃ³ TÃ­nh: NÃ³ cá»±c ká»³ cháº¯c cháº¯n lÃ  "KHÃ”NG" (100%).

Mr. Tiá»m NÄƒng: DÃ¹ cÃ³ má»i chá»‰ sá»‘ tá»‘t, nÃ³ dá»± Ä‘oÃ¡n lÃ  "CÃ“" nhÆ°ng Ä‘á»™ tin cáº­y chá»‰ Ä‘áº¡t 53% (gáº§n nhÆ° 50/50). Äiá»u nÃ y cho tháº¥y Random Forest Ä‘ang tháº¥y dá»¯ liá»‡u khÃ¡ nhiá»…u vÃ  khÃ´ng dÃ¡m kháº³ng Ä‘á»‹nh máº¡nh máº½.



print(f"=== Káº¾T QUáº¢ SUY LUáº¬N Báº°NG LOGISTIC REGRESSION ===")

# Dá»± Ä‘oÃ¡n báº±ng Logistic Regression
preds_lr = lr_model.predict(case_studies_scaled)
probs_lr = lr_model.predict_proba(case_studies_scaled)

for i, name in enumerate(case_studies.index):
    ket_qua = "CÃ“ ÄÄƒng kÃ½ (Yes)" if preds_lr[i] == 1 else "KHÃ”NG ÄÄƒng kÃ½ (No)"
    # Láº¥y xÃ¡c suáº¥t cá»§a lá»›p Ä‘Æ°á»£c dá»± Ä‘oÃ¡n
    do_tin_cay = probs_lr[i][preds_lr[i]]

    print(f"KhÃ¡ch hÃ ng: {name}")
    print(f" -> Logistic Regression dá»± Ä‘oÃ¡n: {ket_qua}")
    print(f" -> Äá»™ tin cáº­y (Confidence): {do_tin_cay:.2%}")
    print("-" * 30)

# --- GIáº¢I THÃCH Táº I SAO (INTERPRETATION) ---
# Xem trá»ng sá»‘ (Weights) Ä‘á»ƒ biáº¿t yáº¿u tá»‘ nÃ o khiáº¿n Logistic Regression quyáº¿t Ä‘á»‹nh nhÆ° váº­y
feature_names = X.columns
weights = lr_model.coef_[0]

print("\n=== Táº I SAO MODEL Láº I Dá»° ÄOÃN NHÆ¯ Váº¬Y? (TRá»ŒNG Sá») ===")
# Táº¡o dataframe Ä‘á»ƒ dá»… nhÃ¬n
weights_df = pd.DataFrame({
    'Yáº¿u tá»‘': feature_names,
    'Trá»ng sá»‘ (Weight)': weights
}).sort_values(by='Trá»ng sá»‘ (Weight)', ascending=False)

display(weights_df.head(5))
print("LÆ°u Ã½: Trá»ng sá»‘ DÆ¯Æ NG lá»›n -> KÃ©o vá» YES. Trá»ng sá»‘ Ã‚M lá»›n -> KÃ©o vá» NO.")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# DECISION TREE (CÃ‚Y QUYáº¾T Äá»ŠNH) ---

print(f"=== Káº¾T QUáº¢ SUY LUáº¬N Báº°NG DECISION TREE ===")

preds_dt = dt_model.predict(case_studies)
probs_dt = dt_model.predict_proba(case_studies)

for i, name in enumerate(case_studies.index):
    ket_qua = "CÃ“ ÄÄƒng kÃ½ (Yes)" if preds_dt[i] == 1 else "KHÃ”NG ÄÄƒng kÃ½ (No)"
    do_tin_cay = probs_dt[i][preds_dt[i]]
    print(f"KhÃ¡ch hÃ ng: {name}")
    print(f" -> Decision Tree phÃ¡n: {ket_qua}")
    print(f" -> Äá»™ tin cáº­y: {do_tin_cay:.2%}")
    print("-" * 30)

# Xem Decision Tree coi trá»ng yáº¿u tá»‘ nÃ o nháº¥t
print("\n[Decision Tree] Top 3 yáº¿u tá»‘ quan trá»ng nháº¥t:")
dt_importance = pd.Series(dt_model.feature_importances_, index=X.columns).sort_values(ascending=False).head(3)
print(dt_importance)


print("\n" + "="*50 + "\n")


# --- MÃ” HÃŒNH KNN (K-LÃNG GIá»€NG Gáº¦N NHáº¤T) ---
# LÆ°u Ã½: KNN tÃ­nh khoáº£ng cÃ¡ch nÃªn Báº®T BUá»˜C dÃ¹ng dá»¯ liá»‡u Ä‘Ã£ chuáº©n hÃ³a (case_studies_scaled)
print(f"=== Káº¾T QUáº¢ SUY LUáº¬N Báº°NG KNN ===")

preds_knn = knn_model.predict(case_studies_scaled)
probs_knn = knn_model.predict_proba(case_studies_scaled)

for i, name in enumerate(case_studies.index):
    ket_qua = "CÃ“ ÄÄƒng kÃ½ (Yes)" if preds_knn[i] == 1 else "KHÃ”NG ÄÄƒng kÃ½ (No)"
    do_tin_cay = probs_knn[i][preds_knn[i]]
    print(f"KhÃ¡ch hÃ ng: {name}")
    print(f" -> KNN phÃ¡n: {ket_qua}")
    print(f" -> Äá»™ tin cáº­y: {do_tin_cay:.2%}") # Dá»±a trÃªn tá»· lá»‡ phiáº¿u báº§u cá»§a 5 hÃ ng xÃ³m
    print("-" * 30)

Decision Tree (CÃ¢y Quyáº¿t Äá»‹nh):

Dá»± Ä‘oÃ¡n: Mr. Tiá»m NÄƒng lÃ  YES vá»›i Ä‘á»™ tin cáº­y 64.19%.
Discount Applied chiáº¿m tá»›i 94% táº§m quan trá»ng.

Káº¿t luáº­n: CÃ¢y quyáº¿t Ä‘á»‹nh nÃ y gáº§n nhÆ° chá»‰ quan tÃ¢m duy nháº¥t má»™t Ä‘iá»u: "KhÃ¡ch cÃ³ mÃ£ giáº£m giÃ¡ khÃ´ng?". Náº¿u cÃ³ -> Kháº£ nÄƒng cao lÃ  Yes. CÃ¡c yáº¿u tá»‘ khÃ¡c (Tiá»n, Tuá»•i) gáº§n nhÆ° bá»‹ bá» qua.
KNN (K-LÃ¡ng Giá»ng):

Dá»± Ä‘oÃ¡n: Mr. Tiá»m NÄƒng lÃ  YES vá»›i Ä‘á»™ tin cáº­y 80% (Cao nháº¥t trong táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh!).

Giáº£i thÃ­ch: Äiá»u nÃ y cÃ³ nghÄ©a lÃ  trong 5 khÃ¡ch hÃ ng cÅ© giá»‘ng há»‡t Mr. Tiá»m NÄƒng (vá» hÃ nh vi, nhÃ¢n kháº©u), cÃ³ tá»›i 4 ngÆ°á»i Ä‘Ã£ mua Subscription.

Káº¿t luáº­n: KNN cá»±c ká»³ hiá»‡u quáº£ trong viá»‡c tÃ¬m kiáº¿m nhá»¯ng há»“ sÆ¡ tÆ°Æ¡ng Ä‘á»“ng (Look-alike audience).

So sÃ¡nh Ä‘á»™ tá»± tin: Random Forest vs. Logistic Regression
Vá»›i Mr. Tiá»m NÄƒng (Logic Tá»‘t):

Random Forest: Dá»± Ä‘oÃ¡n YES, Ä‘á»™ tin cáº­y 53% (Ráº¥t lÆ°á»¡ng lá»±).

Logistic Regression: Dá»± Ä‘oÃ¡n YES, Ä‘á»™ tin cáº­y 60.96% (Tá»± tin hÆ¡n má»™t chÃºt).

Káº¿t luáº­n: Logistic Regression hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n trong viá»‡c náº¯m báº¯t xu hÆ°á»›ng tuyáº¿n tÃ­nh cá»§a bá»™ dá»¯ liá»‡u nÃ y.

Vá»›i Ms. KhÃ³ TÃ­nh (Logic Xáº¥u):

Cáº£ hai mÃ´ hÃ¬nh Ä‘á»u Ä‘á»“ng lÃ²ng 100% (hoáº·c 99.98%) lÃ  KHÃ”NG.

Äiá»u nÃ y chá»©ng tá»: Táº­p dá»¯ liá»‡u cÃ³ nhá»¯ng Ä‘áº·c Ä‘iá»ƒm "chÃ­ máº¡ng" khiáº¿n mÃ´ hÃ¬nh loáº¡i ngay láº­p tá»©c nhá»¯ng khÃ¡ch hÃ ng nhÆ° Ms. KhÃ³ TÃ­nh.

#Káº¿t luáº­n

KNN (K-LÃ¡ng Giá»ng)	YES	80.00. TÃ¬m ra 4/5 khÃ¡ch hÃ ng cÅ© cÃ³ há»“ sÆ¡ y há»‡t Ä‘Ã£ mua hÃ ng. Hiá»‡u quáº£ nháº¥t cho khÃ¡ch hÃ ng tÆ°Æ¡ng Ä‘á»“ng.
============================

Decision Tree	YES	64.19%	Quyáº¿t Ä‘oÃ¡n. Chá»‰ quan tÃ¢m duy nháº¥t má»™t cÃ¢u há»i: "KhÃ¡ch cÃ³ mÃ£ giáº£m giÃ¡ khÃ´ng?". ÄÆ¡n giáº£n, dá»… giáº£i thÃ­ch.
==========


Logistic Regression	YES	60.96%	CÃ¢n báº±ng. PhÃ¡t hiá»‡n ra cáº£ yáº¿u tá»‘ Giá»›i tÃ­nh vÃ  Khuyáº¿n mÃ£i áº£nh hÆ°á»Ÿng Ä‘áº¿n quyáº¿t Ä‘á»‹nh.
==========

Random Forest	YES	53.00%	Tháº­n trá»ng. Tá»· lá»‡ gáº§n nhÆ° 50/50, cho tháº¥y dá»¯ liá»‡u cÃ³ Ä‘á»™ nhiá»…u khiáº¿n mÃ´ hÃ¬nh khÃ´ng dÃ¡m kháº³ng Ä‘á»‹nh cháº¯c cháº¯n.
=====


Náº¿u muá»‘n Tá»¶ Lá»† CHá»T ÄÆ N cao nháº¥t (Marketing Campaign)
ğŸ‘‰ Chá»n KNN (K-Nearest Neighbors)
===================================================================

